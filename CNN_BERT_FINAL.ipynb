{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwedKi8ztJOy",
    "outputId": "6037030b-e45c-4754-cf64-38272aa393ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=7c55e2e73c2569bc90bec07be8cc9cb7eeb3f7d7ac24f1463ce6fed3ede0c4cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.2.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting emot\n",
      "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emot\n",
      "Successfully installed emot-3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "!pip install emoji\n",
    "!pip install emot\n",
    "!pip install --upgrade emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sixTR4y0MIXe",
    "outputId": "028102db-90de-4b1f-818f-58e4eceb80ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KuTl1VnNfsX"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import ToktokTokenizer\n",
    "import nltk\n",
    "import gc\n",
    "#import os\n",
    "import emoji as emoji\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoModel\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "############################################################################\n",
    "                            # OUR CONTRIBUTION #\n",
    "############################################################################\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased', num_labels=3)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(442, 3) # before : 442 with max_length 36 # 806 with max_length 64\n",
    "        self.flat = nn.Flatten()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        _, _, hidden_states = self.bert(sent_id, attention_mask=mask, output_hidden_states=True,return_dict=False)\n",
    "        # all_layers  = [13, 32, 64, 768]\n",
    "        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in hidden_states]), 0), 0, 1)\n",
    "        \n",
    "        x= torch.tensor(x)\n",
    "\n",
    "        del hidden_states\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n",
    "        x = self.fc(self.dropout(self.flat(self.dropout(x))))\n",
    "        return self.softmax(x)\n",
    "\n",
    "\n",
    "def read_dataset(path):\n",
    "    data = pd.read_csv(path)\n",
    "    print(len(data))\n",
    "    return data['text'], data['label']\n",
    "\n",
    "\n",
    "def pre_process_dataset(text):\n",
    "    text = str(text)\n",
    "    text = deEmojify(text) #remove emojis\n",
    "    text = re.sub(r'([\\.\\'\\\"\\/\\-\\_\\--])',' ', text) # remove punctuations , removes @USER / some abbreviatins\n",
    "    to_remove_url = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "      '[!*,]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    text = re.sub(to_remove_url,'',text)  # remove url patterns\n",
    "    text = re.sub(\" \\d+\", \" \", text)\n",
    "    text = text.replace(\",\",\" \")\n",
    "    text = re.sub(r'(?:^| )\\w(?:$| )', ' ', text).strip()\n",
    "    punctuation='!!\"$%&()*+-/:;<=>?[\\]^_{|}~.'\n",
    "    text = ''.join(ch for ch in text if ch not in set(punctuation))\n",
    "    \n",
    "    tokenizer = ToktokTokenizer()\n",
    "    # convert sentence into token of words\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    text = ' '.join(ch for ch in tokens)\n",
    "    return text\n",
    "\n",
    "def deEmojify(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                              u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                              u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                              u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                              u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                              u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                              u\"\\U00002702-\\U000027B0\"\n",
    "                              u\"\\U00002702-\\U000027B0\"\n",
    "                              u\"\\U000024C2-\\U0001F251\"\n",
    "                              u\"\\U0001f926-\\U0001f937\"\n",
    "                              u\"\\U00010000-\\U0010ffff\"\n",
    "                              u\"\\u2640-\\u2642\"\n",
    "                              u\"\\u2600-\\u2B55\"\n",
    "                              u\"\\u200d\"\n",
    "                              u\"\\u23cf\"\n",
    "                              u\"\\u23e9\"\n",
    "                              u\"\\u231a\"\n",
    "                              u\"\\ufe0f\"  # dingbats\n",
    "                              u\"\\u3030\"\n",
    "                              \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxHFB6oHrfuV"
   },
   "outputs": [],
   "source": [
    "def data_process(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    for sentence in data:\n",
    "        bert_inp = bert_tokenizer.__call__(sentence, max_length=36,\n",
    "                                           padding='max_length', pad_to_max_length=True,\n",
    "                                           truncation=True, return_token_type_ids=False)\n",
    "\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "    #del bert_tokenizer\n",
    "    #gc.collect()\n",
    "    #torch.cuda.empty_cache()\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    attention_masks = np.array(attention_masks)\n",
    "    labels = np.array(labels)\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "def load_and_process(path):\n",
    "    data, labels = read_dataset(path)\n",
    "    num_of_labels = len(labels.unique())\n",
    "    data = data.apply(lambda x: pre_process_dataset(x))\n",
    "    input_ids, attention_masks, labels = data_process(data, labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        #sent_id = torch.tensor(sent_id).to(device).long()\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        #preds = preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        #total_preds.append(preds)\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_J0W9QmIrTgA",
    "outputId": "9bea5f30-53cd-4e71-bc47-f86e431cee93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\n\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    total = len(val_dataloader)\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        \n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            #preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            #total_preds.append(preds)\n",
    "            for logits in preds.detach().cpu().numpy():\n",
    "                total_preds.append(np.argmax(logits))\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "# Specify the GPU\n",
    "# Setting up the device for GPU usage\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "referenced_widgets": [
      "754f298c329f47739e0a099a2d93792b",
      "41ab3807c0464fd3b8e9af70f2f3e2bc",
      "afb84612bd7a40908f65feee114ece40",
      "854b568eb74f497fb303d1f938cb1007",
      "625830d3f8a7422785185a61d07b3bec",
      "a8dbbcb1878749fa918e4cadbc6f0e21",
      "564883214c1c4ebca7d421dfe8c55885",
      "28c26a84211543d296c566118d2279bc",
      "a58177e3ba8042758fbb4af2be321ec8",
      "4275ac67db464317bad92cd355517611",
      "16de7642cfb94104bf35b99400721d3c",
      "a592dc8904a94f21bf49ee66e1bfdc4e",
      "77ed0142bfd54b9c8cb8fde4772c52db",
      "5dce9ed2f25a455b96ef727b9472a0e9",
      "00468c75c78a4c33a9a053255b247788",
      "08c82ea026fd4f86b8f6a0fe08600d22",
      "0a8bd78058db499ab7d597789681f1f1",
      "1e47c6d21c2247f7a9b7267950e210c4",
      "6e283d230b7045858f935ae6d52b1c13",
      "09a7af7412f84e8b8a4fd4c1b6ceb3ea",
      "8e904804f1b44b8c833476aca3ecfe77",
      "4e01af6518134569914e7f16e1b4ec04",
      "a017f3c6cf3c436297ae7e3643142769",
      "c403df7f48c84db5938785a9a04f41ad",
      "edee5f46e2ef484fa6932eb3392e959e",
      "e4dbb5d1841e48ec8dfe35916a14218b",
      "02507cbc35244158b981d080797bb661",
      "26b1845f7c0146dd8570f792bf8e77f3",
      "02cf1ef1bb574cd0a8bead0b4b39de46",
      "b9fde07332024fbe97996085b021736b",
      "336403f1c0c9430186d1c88c1c3504c5",
      "1a0894b354f842f392a0f28196aeecc2",
      "80f4d49ed01642dd9b555cd6207d9748",
      "7ddca4fadc8c4b2db6210e9aa3172e1d",
      "447045fe980b4ec8905d4f9495375f4c",
      "7416c6da180d48e8acc0698a1ba9b05f",
      "bc8e88899f3942e1964254646d806e43",
      "c471bdbc515940eead9c96946a594f43",
      "189c6462758f492b9ef2653394f51e8b",
      "8ac9b40f34b04e1d948b86d48ac35c27",
      "c05ff3ebebc04d0b951c41e23cb3686b",
      "fd8506d5b5894a51aac5b86bfd704cbf",
      "6f68045d4b8e4e3596612de0bc428f65",
      "2afb1be367734f4a81c5bb4ca8093206"
     ]
    },
    "id": "M2NTPBa-E9Xb",
    "outputId": "e8862292-1e02-40e2-dfda-71ef07c6f7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754f298c329f47739e0a099a2d93792b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a592dc8904a94f21bf49ee66e1bfdc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a017f3c6cf3c436297ae7e3643142769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4388\n",
      "[0 2 0 ... 0 2 0]\n",
      "[0 0 2 ... 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d3aeaace2879>:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  train_seq = torch.tensor(df_train['input_ids'].tolist())\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddca4fadc8c4b2db6210e9aa3172e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "path_train = '/content/drive/MyDrive/tamil_train.csv'\n",
    "path_val = '/content/drive/MyDrive/tamil_dev.csv'\n",
    "\n",
    "# Load and process the training dataset\n",
    "input_ids_train, attention_masks_train, train_labels = load_and_process(path_train)\n",
    "df_train = pd.DataFrame(list(zip(input_ids_train, attention_masks_train)), columns=['input_ids', 'attention_masks'])\n",
    "\n",
    "# Load and process the validation dataset\n",
    "input_ids_test, attention_masks_test, val_labels = load_and_process(path_val)\n",
    "df_val = pd.DataFrame(list(zip(input_ids_test, attention_masks_test)), columns=['input_ids', 'attention_masks'])\n",
    "\n",
    "del input_ids_train, attention_masks_train, input_ids_test, attention_masks_test\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# replace values in the train_labels array\n",
    "train_labels = np.where(train_labels == 'Not_offensive', 0, train_labels)\n",
    "train_labels = np.where(train_labels == 'Offensive', 1, train_labels)\n",
    "train_labels = np.where(train_labels == 'not-Tamil', 2, train_labels)\n",
    "\n",
    "print(train_labels)\n",
    "\n",
    "val_labels = np.where(val_labels == 'Not_offensive', 0, val_labels)\n",
    "val_labels = np.where(val_labels== 'Offensive', 1, val_labels)\n",
    "val_labels = np.where(val_labels == 'not-Tamil', 2, val_labels)\n",
    "\n",
    "print(val_labels)\n",
    "\n",
    "\n",
    "# Tokenize train set\n",
    "train_seq = torch.tensor(df_train['input_ids'].tolist())\n",
    "train_mask = torch.tensor(df_train['attention_masks'].tolist())\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize validation set\n",
    "val_seq = torch.tensor(df_val['input_ids'].tolist())\n",
    "val_mask = torch.tensor(df_val['attention_masks'].tolist())\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "train_count = len(df_train)\n",
    "val_count = len(df_val)\n",
    "\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-multilingual-cased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpgUCPouLWx8",
    "outputId": "cee8d778-19aa-4664-a329-de0d5c57f0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n97iZECrD2d"
   },
   "outputs": [],
   "source": [
    "#Create DataLoaders\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# define a batch size\n",
    "batch_size = 16\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkSwMw14q6au",
    "outputId": "017dbe1e-c3f3-4fa5-863b-90188cd4a0d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "\r",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.027\n",
      "Validation Loss: 0.028\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      3193\n",
      "           1       0.61      0.52      0.56      1023\n",
      "           2       0.89      0.62      0.73       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.78      0.68      0.72      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.7971741112123975\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.026\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      3193\n",
      "           1       0.64      0.46      0.54      1023\n",
      "           2       0.86      0.63      0.73       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.78      0.67      0.71      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8005925250683683\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.026\n",
      "Validation Loss: 0.028\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.87      3193\n",
      "           1       0.65      0.48      0.55      1023\n",
      "           2       0.84      0.66      0.74       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.77      0.69      0.72      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8044667274384686\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.025\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.87      3193\n",
      "           1       0.65      0.48      0.55      1023\n",
      "           2       0.82      0.68      0.75       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.77      0.69      0.72      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8044667274384686\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.025\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88      3193\n",
      "           1       0.67      0.43      0.52      1023\n",
      "           2       0.86      0.62      0.72       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.78      0.66      0.71      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8028714676390155\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.024\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      3193\n",
      "           1       0.70      0.43      0.53      1023\n",
      "           2       0.89      0.59      0.71       172\n",
      "\n",
      "    accuracy                           0.81      4388\n",
      "   macro avg       0.80      0.65      0.70      4388\n",
      "weighted avg       0.80      0.81      0.79      4388\n",
      "\n",
      "Accuracy: 0.8067456700091158\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.024\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      3193\n",
      "           1       0.68      0.43      0.53      1023\n",
      "           2       0.87      0.60      0.71       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.79      0.66      0.71      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8033272561531449\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.023\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      3193\n",
      "           1       0.60      0.57      0.59      1023\n",
      "           2       0.80      0.66      0.72       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.75      0.70      0.72      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.7964904284412033\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.023\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      3193\n",
      "           1       0.66      0.45      0.53      1023\n",
      "           2       0.92      0.56      0.70       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.80      0.65      0.70      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.8024156791248861\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.023\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      3193\n",
      "           1       0.63      0.54      0.58      1023\n",
      "           2       0.87      0.62      0.72       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.78      0.69      0.73      4388\n",
      "weighted avg       0.80      0.80      0.80      4388\n",
      "\n",
      "Accuracy: 0.8046946216955333\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.023\n",
      "Validation Loss: 0.030\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      3193\n",
      "           1       0.67      0.44      0.53      1023\n",
      "           2       0.86      0.59      0.70       172\n",
      "\n",
      "    accuracy                           0.80      4388\n",
      "   macro avg       0.78      0.65      0.70      4388\n",
      "weighted avg       0.79      0.80      0.79      4388\n",
      "\n",
      "Accuracy: 0.800820419325433\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.022\n",
      "Validation Loss: 0.029\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      3193\n",
      "           1       0.64      0.53      0.58      1023\n",
      "           2       0.80      0.67      0.73       172\n",
      "\n",
      "    accuracy                           0.81      4388\n",
      "   macro avg       0.77      0.70      0.73      4388\n",
      "weighted avg       0.80      0.81      0.80      4388\n",
      "\n",
      "Accuracy: 0.8078851412944393\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.022\n",
      "Validation Loss: 0.030\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      3193\n",
      "           1       0.59      0.60      0.59      1023\n",
      "           2       0.88      0.59      0.70       172\n",
      "\n",
      "    accuracy                           0.79      4388\n",
      "   macro avg       0.77      0.68      0.72      4388\n",
      "weighted avg       0.80      0.79      0.79      4388\n",
      "\n",
      "Accuracy: 0.7946672743846855\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.022\n",
      "Validation Loss: 0.030\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      3193\n",
      "           1       0.64      0.54      0.59      1023\n",
      "           2       0.89      0.59      0.71       172\n",
      "\n",
      "    accuracy                           0.81      4388\n",
      "   macro avg       0.79      0.68      0.72      4388\n",
      "weighted avg       0.80      0.81      0.80      4388\n",
      "\n",
      "Accuracy: 0.8069735642661805\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.021\n",
      "Validation Loss: 0.031\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      3193\n",
      "           1       0.69      0.44      0.54      1023\n",
      "           2       0.83      0.69      0.75       172\n",
      "\n",
      "    accuracy                           0.81      4388\n",
      "   macro avg       0.78      0.69      0.72      4388\n",
      "weighted avg       0.80      0.81      0.79      4388\n",
      "\n",
      "Accuracy: 0.8085688240656336\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2197/2197 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n",
      "\n",
      "Evaluating...\n",
      "Batch 275/275 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n",
      "\n",
      "Training Loss: 0.021\n",
      "Validation Loss: 0.031\n",
      "Performance:\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      3193\n",
      "           1       0.67      0.43      0.53      1023\n",
      "           2       0.85      0.70      0.77       172\n",
      "\n",
      "    accuracy                           0.81      4388\n",
      "   macro avg       0.78      0.69      0.72      4388\n",
      "weighted avg       0.79      0.81      0.79      4388\n",
      "\n",
      "Accuracy: 0.8053783044667274\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 1/2197 |>...................................................................................................| 0.05% complete, loss=0.00, accuracy=0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-528b438650ee>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 216/2197 |█████████>..........................................................................................| 9.83% complete, loss=0.00, accuracy=0"
     ]
    }
   ],
   "source": [
    "# Freeze BERT Parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss()\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#model.load_state_dict(torch.load(\"/content/drive/MyDrive/FYP/finetuned_models/bert_cnn.pth\"), strict=False)\n",
    "\n",
    "epochs = 20\n",
    "current = 1\n",
    "val_preds = []\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss, _ = train()\n",
    "\n",
    "    # evaluate model\n",
    "    valid_loss, val_preds = evaluate()\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '/content/drive/MyDrive/FYP/finetuned_models/bert_cnn.pth')\n",
    "\n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "    current = current + 1\n",
    "\n",
    "    print(\"Performance:\")\n",
    "    # model's performance\n",
    "    #preds = np.argmax(preds, axis=1)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(val_y, val_preds))\n",
    "    print(\"Accuracy: \" + str(accuracy_score(val_y, val_preds)))\n",
    "\n",
    "# get predictions for test data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pj3Rgv_WKJfo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00468c75c78a4c33a9a053255b247788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e904804f1b44b8c833476aca3ecfe77",
      "placeholder": "​",
      "style": "IPY_MODEL_4e01af6518134569914e7f16e1b4ec04",
      "value": " 29.0/29.0 [00:00&lt;00:00, 475B/s]"
     }
    },
    "02507cbc35244158b981d080797bb661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02cf1ef1bb574cd0a8bead0b4b39de46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08c82ea026fd4f86b8f6a0fe08600d22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09a7af7412f84e8b8a4fd4c1b6ceb3ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a8bd78058db499ab7d597789681f1f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16de7642cfb94104bf35b99400721d3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "189c6462758f492b9ef2653394f51e8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a0894b354f842f392a0f28196aeecc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e47c6d21c2247f7a9b7267950e210c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26b1845f7c0146dd8570f792bf8e77f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c26a84211543d296c566118d2279bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "2afb1be367734f4a81c5bb4ca8093206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "336403f1c0c9430186d1c88c1c3504c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "41ab3807c0464fd3b8e9af70f2f3e2bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8dbbcb1878749fa918e4cadbc6f0e21",
      "placeholder": "​",
      "style": "IPY_MODEL_564883214c1c4ebca7d421dfe8c55885",
      "value": "Downloading (…)solve/main/vocab.txt: "
     }
    },
    "4275ac67db464317bad92cd355517611": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "447045fe980b4ec8905d4f9495375f4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_189c6462758f492b9ef2653394f51e8b",
      "placeholder": "​",
      "style": "IPY_MODEL_8ac9b40f34b04e1d948b86d48ac35c27",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "4e01af6518134569914e7f16e1b4ec04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "564883214c1c4ebca7d421dfe8c55885": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dce9ed2f25a455b96ef727b9472a0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e283d230b7045858f935ae6d52b1c13",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09a7af7412f84e8b8a4fd4c1b6ceb3ea",
      "value": 29
     }
    },
    "625830d3f8a7422785185a61d07b3bec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e283d230b7045858f935ae6d52b1c13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f68045d4b8e4e3596612de0bc428f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7416c6da180d48e8acc0698a1ba9b05f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c05ff3ebebc04d0b951c41e23cb3686b",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd8506d5b5894a51aac5b86bfd704cbf",
      "value": 714314041
     }
    },
    "754f298c329f47739e0a099a2d93792b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41ab3807c0464fd3b8e9af70f2f3e2bc",
       "IPY_MODEL_afb84612bd7a40908f65feee114ece40",
       "IPY_MODEL_854b568eb74f497fb303d1f938cb1007"
      ],
      "layout": "IPY_MODEL_625830d3f8a7422785185a61d07b3bec"
     }
    },
    "77ed0142bfd54b9c8cb8fde4772c52db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a8bd78058db499ab7d597789681f1f1",
      "placeholder": "​",
      "style": "IPY_MODEL_1e47c6d21c2247f7a9b7267950e210c4",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "7ddca4fadc8c4b2db6210e9aa3172e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_447045fe980b4ec8905d4f9495375f4c",
       "IPY_MODEL_7416c6da180d48e8acc0698a1ba9b05f",
       "IPY_MODEL_bc8e88899f3942e1964254646d806e43"
      ],
      "layout": "IPY_MODEL_c471bdbc515940eead9c96946a594f43"
     }
    },
    "80f4d49ed01642dd9b555cd6207d9748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "854b568eb74f497fb303d1f938cb1007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4275ac67db464317bad92cd355517611",
      "placeholder": "​",
      "style": "IPY_MODEL_16de7642cfb94104bf35b99400721d3c",
      "value": " 996k/? [00:00&lt;00:00, 2.90MB/s]"
     }
    },
    "8ac9b40f34b04e1d948b86d48ac35c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e904804f1b44b8c833476aca3ecfe77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a017f3c6cf3c436297ae7e3643142769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c403df7f48c84db5938785a9a04f41ad",
       "IPY_MODEL_edee5f46e2ef484fa6932eb3392e959e",
       "IPY_MODEL_e4dbb5d1841e48ec8dfe35916a14218b"
      ],
      "layout": "IPY_MODEL_02507cbc35244158b981d080797bb661"
     }
    },
    "a58177e3ba8042758fbb4af2be321ec8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a592dc8904a94f21bf49ee66e1bfdc4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77ed0142bfd54b9c8cb8fde4772c52db",
       "IPY_MODEL_5dce9ed2f25a455b96ef727b9472a0e9",
       "IPY_MODEL_00468c75c78a4c33a9a053255b247788"
      ],
      "layout": "IPY_MODEL_08c82ea026fd4f86b8f6a0fe08600d22"
     }
    },
    "a8dbbcb1878749fa918e4cadbc6f0e21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afb84612bd7a40908f65feee114ece40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c26a84211543d296c566118d2279bc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a58177e3ba8042758fbb4af2be321ec8",
      "value": 1
     }
    },
    "b9fde07332024fbe97996085b021736b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc8e88899f3942e1964254646d806e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f68045d4b8e4e3596612de0bc428f65",
      "placeholder": "​",
      "style": "IPY_MODEL_2afb1be367734f4a81c5bb4ca8093206",
      "value": " 714M/714M [00:06&lt;00:00, 125MB/s]"
     }
    },
    "c05ff3ebebc04d0b951c41e23cb3686b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c403df7f48c84db5938785a9a04f41ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26b1845f7c0146dd8570f792bf8e77f3",
      "placeholder": "​",
      "style": "IPY_MODEL_02cf1ef1bb574cd0a8bead0b4b39de46",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "c471bdbc515940eead9c96946a594f43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4dbb5d1841e48ec8dfe35916a14218b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a0894b354f842f392a0f28196aeecc2",
      "placeholder": "​",
      "style": "IPY_MODEL_80f4d49ed01642dd9b555cd6207d9748",
      "value": " 625/625 [00:00&lt;00:00, 17.3kB/s]"
     }
    },
    "edee5f46e2ef484fa6932eb3392e959e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9fde07332024fbe97996085b021736b",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_336403f1c0c9430186d1c88c1c3504c5",
      "value": 625
     }
    },
    "fd8506d5b5894a51aac5b86bfd704cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
